{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23e5d5b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 750\u001b[0m\n\u001b[0;32m    745\u001b[0m         traceback\u001b[38;5;241m.\u001b[39mprint_exc()\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    749\u001b[0m     \u001b[38;5;66;03m# Run the test\u001b[39;00m\n\u001b[1;32m--> 750\u001b[0m     \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\asyncio\\runners.py:33\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m coroutines\u001b[38;5;241m.\u001b[39miscoroutine(main):\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma coroutine was expected, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(main))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "# Simple AgentCore Agents with Orchestration\n",
    "# Step-by-step learning implementation\n",
    "\n",
    "import asyncio\n",
    "import json\n",
    "import boto3\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, Any, List\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "\n",
    "# Initialize the AgentCore application\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "# ================================================================================================\n",
    "# AGENT 1: SIMPLE CALCULATOR AGENT\n",
    "# ================================================================================================\n",
    "\n",
    "@app.entrypoint\n",
    "async def calculator_agent(payload: Dict[str, Any], context) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Simple calculator agent that performs basic mathematical operations\n",
    "    \n",
    "    Input: {\"operation\": \"add\", \"numbers\": [1, 2, 3]}\n",
    "    Output: {\"result\": 6, \"operation\": \"add\", \"timestamp\": \"...\"}\n",
    "    \"\"\"\n",
    "    \n",
    "    operation = payload.get('operation', 'add')\n",
    "    numbers = payload.get('numbers', [0])\n",
    "    \n",
    "    # Ping to maintain session health\n",
    "    await context.ping(status=\"HEALTHY_BUSY\", message=f\"Calculating {operation}\")\n",
    "    \n",
    "    try:\n",
    "        if operation == 'add':\n",
    "            result = sum(numbers)\n",
    "        elif operation == 'subtract':\n",
    "            result = numbers[0] - sum(numbers[1:]) if len(numbers) > 1 else numbers[0]\n",
    "        elif operation == 'multiply':\n",
    "            result = 1\n",
    "            for num in numbers:\n",
    "                result *= num\n",
    "        elif operation == 'divide':\n",
    "            result = numbers[0]\n",
    "            for num in numbers[1:]:\n",
    "                if num != 0:\n",
    "                    result /= num\n",
    "                else:\n",
    "                    return {\"error\": \"Division by zero\", \"agent_type\": \"calculator_agent\"}\n",
    "        elif operation == 'average':\n",
    "            result = sum(numbers) / len(numbers) if numbers else 0\n",
    "        else:\n",
    "            return {\"error\": f\"Unsupported operation: {operation}\", \"agent_type\": \"calculator_agent\"}\n",
    "        \n",
    "        return {\n",
    "            \"result\": result,\n",
    "            \"operation\": operation,\n",
    "            \"numbers_processed\": numbers,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"agent_type\": \"calculator_agent\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"error\": str(e),\n",
    "            \"operation\": operation,\n",
    "            \"agent_type\": \"calculator_agent\"\n",
    "        }\n",
    "\n",
    "\n",
    "# ================================================================================================\n",
    "# AGENT 2: TEXT PROCESSOR AGENT\n",
    "# ================================================================================================\n",
    "\n",
    "@app.entrypoint\n",
    "async def text_processor_agent(payload: Dict[str, Any], context) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Simple text processing agent\n",
    "    \n",
    "    Input: {\"text\": \"Hello World\", \"operations\": [\"uppercase\", \"word_count\"]}\n",
    "    Output: {\"processed_text\": \"HELLO WORLD\", \"word_count\": 2, ...}\n",
    "    \"\"\"\n",
    "    \n",
    "    text = payload.get('text', '')\n",
    "    operations = payload.get('operations', ['word_count'])\n",
    "    \n",
    "    await context.ping(status=\"HEALTHY_BUSY\", message=\"Processing text\")\n",
    "    \n",
    "    results = {\n",
    "        \"original_text\": text,\n",
    "        \"operations_performed\": operations,\n",
    "        \"results\": {},\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"agent_type\": \"text_processor_agent\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        for operation in operations:\n",
    "            if operation == 'uppercase':\n",
    "                results[\"results\"][\"uppercase\"] = text.upper()\n",
    "            elif operation == 'lowercase':\n",
    "                results[\"results\"][\"lowercase\"] = text.lower()\n",
    "            elif operation == 'word_count':\n",
    "                results[\"results\"][\"word_count\"] = len(text.split())\n",
    "            elif operation == 'character_count':\n",
    "                results[\"results\"][\"character_count\"] = len(text)\n",
    "            elif operation == 'reverse':\n",
    "                results[\"results\"][\"reverse\"] = text[::-1]\n",
    "            elif operation == 'title_case':\n",
    "                results[\"results\"][\"title_case\"] = text.title()\n",
    "            else:\n",
    "                results[\"results\"][operation] = f\"Unknown operation: {operation}\"\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"error\": str(e),\n",
    "            \"original_text\": text,\n",
    "            \"agent_type\": \"text_processor_agent\"\n",
    "        }\n",
    "\n",
    "\n",
    "# ================================================================================================\n",
    "# AGENT 3: DATA GENERATOR AGENT\n",
    "# ================================================================================================\n",
    "\n",
    "@app.entrypoint\n",
    "async def data_generator_agent(payload: Dict[str, Any], context) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Simple data generator agent that creates sample datasets\n",
    "    \n",
    "    Input: {\"dataset_type\": \"customers\", \"count\": 100}\n",
    "    Output: {\"dataset\": [...], \"metadata\": {...}}\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset_type = payload.get('dataset_type', 'customers')\n",
    "    count = payload.get('count', 10)\n",
    "    \n",
    "    await context.ping(status=\"HEALTHY_BUSY\", message=f\"Generating {count} {dataset_type} records\")\n",
    "    \n",
    "    import random\n",
    "    \n",
    "    try:\n",
    "        if dataset_type == 'customers':\n",
    "            # Generate customer data\n",
    "            first_names = ['John', 'Jane', 'Bob', 'Alice', 'Charlie', 'Diana', 'Eve', 'Frank']\n",
    "            last_names = ['Smith', 'Johnson', 'Brown', 'Davis', 'Wilson', 'Taylor', 'Anderson', 'Thomas']\n",
    "            domains = ['gmail.com', 'yahoo.com', 'company.com', 'business.org']\n",
    "            \n",
    "            dataset = []\n",
    "            for i in range(count):\n",
    "                first_name = random.choice(first_names)\n",
    "                last_name = random.choice(last_names)\n",
    "                customer = {\n",
    "                    'id': f'CUST_{str(i+1).zfill(4)}',\n",
    "                    'first_name': first_name,\n",
    "                    'last_name': last_name,\n",
    "                    'email': f'{first_name.lower()}.{last_name.lower()}@{random.choice(domains)}',\n",
    "                    'age': random.randint(18, 80),\n",
    "                    'purchase_amount': round(random.uniform(10, 1000), 2),\n",
    "                    'registration_date': (datetime.now() - timedelta(days=random.randint(0, 365))).strftime('%Y-%m-%d')\n",
    "                }\n",
    "                dataset.append(customer)\n",
    "                \n",
    "        elif dataset_type == 'products':\n",
    "            # Generate product data\n",
    "            categories = ['Electronics', 'Clothing', 'Books', 'Home', 'Sports']\n",
    "            product_names = ['Widget', 'Gadget', 'Tool', 'Device', 'Item', 'Product', 'Thing']\n",
    "            \n",
    "            dataset = []\n",
    "            for i in range(count):\n",
    "                product = {\n",
    "                    'id': f'PROD_{str(i+1).zfill(4)}',\n",
    "                    'name': f'{random.choice(product_names)} {i+1}',\n",
    "                    'category': random.choice(categories),\n",
    "                    'price': round(random.uniform(5, 500), 2),\n",
    "                    'stock': random.randint(0, 100),\n",
    "                    'rating': round(random.uniform(1, 5), 1),\n",
    "                    'created_date': (datetime.now() - timedelta(days=random.randint(0, 180))).strftime('%Y-%m-%d')\n",
    "                }\n",
    "                dataset.append(product)\n",
    "                \n",
    "        elif dataset_type == 'sales':\n",
    "            # Generate sales data\n",
    "            dataset = []\n",
    "            for i in range(count):\n",
    "                sale = {\n",
    "                    'id': f'SALE_{str(i+1).zfill(4)}',\n",
    "                    'customer_id': f'CUST_{random.randint(1, 100):04d}',\n",
    "                    'product_id': f'PROD_{random.randint(1, 50):04d}',\n",
    "                    'quantity': random.randint(1, 10),\n",
    "                    'unit_price': round(random.uniform(10, 200), 2),\n",
    "                    'total_amount': 0,  # Will calculate below\n",
    "                    'sale_date': (datetime.now() - timedelta(days=random.randint(0, 90))).strftime('%Y-%m-%d')\n",
    "                }\n",
    "                sale['total_amount'] = round(sale['quantity'] * sale['unit_price'], 2)\n",
    "                dataset.append(sale)\n",
    "                \n",
    "        else:\n",
    "            return {\n",
    "                \"error\": f\"Unsupported dataset type: {dataset_type}\",\n",
    "                \"supported_types\": [\"customers\", \"products\", \"sales\"],\n",
    "                \"agent_type\": \"data_generator_agent\"\n",
    "            }\n",
    "        \n",
    "        # Calculate metadata\n",
    "        metadata = {\n",
    "            \"dataset_type\": dataset_type,\n",
    "            \"record_count\": len(dataset),\n",
    "            \"generated_at\": datetime.now().isoformat(),\n",
    "            \"sample_record\": dataset[0] if dataset else None\n",
    "        }\n",
    "        \n",
    "        if dataset_type in ['customers', 'sales']:\n",
    "            if dataset_type == 'customers':\n",
    "                total_purchase = sum([record['purchase_amount'] for record in dataset])\n",
    "                avg_age = sum([record['age'] for record in dataset]) / len(dataset)\n",
    "                metadata[\"total_purchase_amount\"] = round(total_purchase, 2)\n",
    "                metadata[\"average_age\"] = round(avg_age, 1)\n",
    "            elif dataset_type == 'sales':\n",
    "                total_revenue = sum([record['total_amount'] for record in dataset])\n",
    "                avg_quantity = sum([record['quantity'] for record in dataset]) / len(dataset)\n",
    "                metadata[\"total_revenue\"] = round(total_revenue, 2)\n",
    "                metadata[\"average_quantity\"] = round(avg_quantity, 1)\n",
    "        \n",
    "        return {\n",
    "            \"dataset\": dataset,\n",
    "            \"metadata\": metadata,\n",
    "            \"agent_type\": \"data_generator_agent\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"error\": str(e),\n",
    "            \"dataset_type\": dataset_type,\n",
    "            \"agent_type\": \"data_generator_agent\"\n",
    "        }\n",
    "\n",
    "\n",
    "# ================================================================================================\n",
    "# AGENT 4: SIMPLE ANALYTICS AGENT\n",
    "# ================================================================================================\n",
    "\n",
    "@app.entrypoint\n",
    "async def simple_analytics_agent(payload: Dict[str, Any], context) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Simple analytics agent that processes data and generates insights\n",
    "    \n",
    "    Input: {\"data\": [...], \"analysis_type\": \"summary\"}\n",
    "    Output: {\"analytics\": {...}, \"insights\": [...]}\n",
    "    \"\"\"\n",
    "    \n",
    "    data = payload.get('data', [])\n",
    "    analysis_type = payload.get('analysis_type', 'summary')\n",
    "    \n",
    "    await context.ping(status=\"HEALTHY_BUSY\", message=f\"Analyzing {len(data)} records\")\n",
    "    \n",
    "    if not data:\n",
    "        return {\n",
    "            \"error\": \"No data provided for analysis\",\n",
    "            \"agent_type\": \"simple_analytics_agent\"\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        analytics = {\n",
    "            \"analysis_type\": analysis_type,\n",
    "            \"record_count\": len(data),\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        insights = []\n",
    "        \n",
    "        if analysis_type == 'summary':\n",
    "            # Basic summary statistics\n",
    "            if isinstance(data[0], dict):\n",
    "                # Analyze dictionary data\n",
    "                keys = data[0].keys()\n",
    "                analytics[\"fields_analyzed\"] = list(keys)\n",
    "                \n",
    "                for key in keys:\n",
    "                    values = [record.get(key) for record in data if record.get(key) is not None]\n",
    "                    \n",
    "                    if values:\n",
    "                        if isinstance(values[0], (int, float)):\n",
    "                            # Numeric field analysis\n",
    "                            analytics[f\"{key}_stats\"] = {\n",
    "                                \"min\": min(values),\n",
    "                                \"max\": max(values),\n",
    "                                \"avg\": round(sum(values) / len(values), 2),\n",
    "                                \"count\": len(values)\n",
    "                            }\n",
    "                            \n",
    "                            if max(values) > sum(values) / len(values) * 2:\n",
    "                                insights.append(f\"High variability detected in {key}\")\n",
    "                                \n",
    "                        elif isinstance(values[0], str):\n",
    "                            # String field analysis\n",
    "                            unique_values = list(set(values))\n",
    "                            analytics[f\"{key}_stats\"] = {\n",
    "                                \"unique_count\": len(unique_values),\n",
    "                                \"total_count\": len(values),\n",
    "                                \"sample_values\": unique_values[:5]\n",
    "                            }\n",
    "                            \n",
    "                            if len(unique_values) < len(values) * 0.1:\n",
    "                                insights.append(f\"Low diversity in {key} - consider categorization\")\n",
    "            else:\n",
    "                # Simple list analysis\n",
    "                if all(isinstance(x, (int, float)) for x in data):\n",
    "                    analytics[\"numeric_stats\"] = {\n",
    "                        \"min\": min(data),\n",
    "                        \"max\": max(data),\n",
    "                        \"avg\": round(sum(data) / len(data), 2),\n",
    "                        \"sum\": sum(data)\n",
    "                    }\n",
    "                    \n",
    "        elif analysis_type == 'trends':\n",
    "            # Look for trends in the data\n",
    "            if isinstance(data[0], dict) and 'date' in data[0]:\n",
    "                # Date-based trend analysis\n",
    "                dates = [record['date'] for record in data if 'date' in record]\n",
    "                analytics[\"date_range\"] = {\n",
    "                    \"earliest\": min(dates),\n",
    "                    \"latest\": max(dates),\n",
    "                    \"span_days\": (datetime.strptime(max(dates), '%Y-%m-%d') - \n",
    "                                datetime.strptime(min(dates), '%Y-%m-%d')).days\n",
    "                }\n",
    "                insights.append(\"Time series data detected - suitable for trend analysis\")\n",
    "                \n",
    "        elif analysis_type == 'quality':\n",
    "            # Data quality analysis\n",
    "            if isinstance(data[0], dict):\n",
    "                total_records = len(data)\n",
    "                quality_metrics = {}\n",
    "                \n",
    "                for key in data[0].keys():\n",
    "                    null_count = sum(1 for record in data if record.get(key) is None or record.get(key) == '')\n",
    "                    quality_metrics[key] = {\n",
    "                        \"completeness\": round((total_records - null_count) / total_records, 3),\n",
    "                        \"missing_count\": null_count\n",
    "                    }\n",
    "                    \n",
    "                    if quality_metrics[key][\"completeness\"] < 0.9:\n",
    "                        insights.append(f\"Data quality issue: {key} has {quality_metrics[key]['completeness']:.1%} completeness\")\n",
    "                \n",
    "                analytics[\"quality_metrics\"] = quality_metrics\n",
    "        \n",
    "        # General insights\n",
    "        if len(data) < 10:\n",
    "            insights.append(\"Small dataset size - consider collecting more data for better analysis\")\n",
    "        elif len(data) > 1000:\n",
    "            insights.append(\"Large dataset detected - suitable for advanced analytics\")\n",
    "        \n",
    "        return {\n",
    "            \"analytics\": analytics,\n",
    "            \"insights\": insights,\n",
    "            \"agent_type\": \"simple_analytics_agent\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"error\": str(e),\n",
    "            \"analysis_type\": analysis_type,\n",
    "            \"agent_type\": \"simple_analytics_agent\"\n",
    "        }\n",
    "\n",
    "\n",
    "# ================================================================================================\n",
    "# SIMPLE ORCHESTRATOR AGENT\n",
    "# ================================================================================================\n",
    "\n",
    "@app.entrypoint\n",
    "async def simple_orchestrator(payload: Dict[str, Any], context) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Simple orchestrator that coordinates multiple agents in sequence\n",
    "    \n",
    "    Input: {\n",
    "        \"workflow\": [\n",
    "            {\"agent\": \"data_generator\", \"params\": {...}},\n",
    "            {\"agent\": \"analytics\", \"params\": {...}}\n",
    "        ]\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    workflow = payload.get('workflow', [])\n",
    "    orchestration_id = f\"simple_orch_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    \n",
    "    orchestration_results = {\n",
    "        \"orchestration_id\": orchestration_id,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"workflow_steps\": len(workflow),\n",
    "        \"step_results\": [],\n",
    "        \"overall_status\": \"in_progress\"\n",
    "    }\n",
    "    \n",
    "    await context.ping(status=\"HEALTHY_BUSY\", message=f\"Starting orchestration with {len(workflow)} steps\")\n",
    "    \n",
    "    try:\n",
    "        for step_index, step in enumerate(workflow):\n",
    "            step_start_time = datetime.now()\n",
    "            agent_type = step.get('agent')\n",
    "            params = step.get('params', {})\n",
    "            \n",
    "            await context.ping(status=\"HEALTHY_BUSY\", message=f\"Executing step {step_index + 1}: {agent_type}\")\n",
    "            \n",
    "            # Execute the appropriate agent based on type\n",
    "            if agent_type == 'calculator':\n",
    "                result = await calculator_agent(params, context)\n",
    "            elif agent_type == 'text_processor':\n",
    "                result = await text_processor_agent(params, context)\n",
    "            elif agent_type == 'data_generator':\n",
    "                result = await data_generator_agent(params, context)\n",
    "            elif agent_type == 'analytics':\n",
    "                result = await simple_analytics_agent(params, context)\n",
    "            else:\n",
    "                result = {\"error\": f\"Unknown agent type: {agent_type}\"}\n",
    "            \n",
    "            step_duration = (datetime.now() - step_start_time).total_seconds()\n",
    "            \n",
    "            step_result = {\n",
    "                \"step_index\": step_index + 1,\n",
    "                \"agent_type\": agent_type,\n",
    "                \"status\": \"success\" if \"error\" not in result else \"failed\",\n",
    "                \"duration_seconds\": step_duration,\n",
    "                \"result\": result\n",
    "            }\n",
    "            \n",
    "            orchestration_results[\"step_results\"].append(step_result)\n",
    "            \n",
    "            # If this step failed, we might want to continue or stop\n",
    "            if \"error\" in result:\n",
    "                orchestration_results[\"overall_status\"] = \"failed_with_errors\"\n",
    "                # For now, continue with remaining steps\n",
    "        \n",
    "        # Determine overall status\n",
    "        successful_steps = len([step for step in orchestration_results[\"step_results\"] \n",
    "                               if step[\"status\"] == \"success\"])\n",
    "        total_steps = len(orchestration_results[\"step_results\"])\n",
    "        \n",
    "        if successful_steps == total_steps:\n",
    "            orchestration_results[\"overall_status\"] = \"completed_successfully\"\n",
    "        elif successful_steps > 0:\n",
    "            orchestration_results[\"overall_status\"] = \"partially_completed\"\n",
    "        else:\n",
    "            orchestration_results[\"overall_status\"] = \"failed\"\n",
    "        \n",
    "        # Add summary\n",
    "        orchestration_results[\"summary\"] = {\n",
    "            \"total_steps\": total_steps,\n",
    "            \"successful_steps\": successful_steps,\n",
    "            \"failed_steps\": total_steps - successful_steps,\n",
    "            \"total_duration_seconds\": sum([step[\"duration_seconds\"] for step in orchestration_results[\"step_results\"]]),\n",
    "            \"completion_time\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        orchestration_results[\"agent_type\"] = \"simple_orchestrator\"\n",
    "        \n",
    "        return orchestration_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        orchestration_results[\"overall_status\"] = \"orchestration_failed\"\n",
    "        orchestration_results[\"error\"] = str(e)\n",
    "        return orchestration_results\n",
    "\n",
    "\n",
    "# ================================================================================================\n",
    "# WORKFLOW TEMPLATES\n",
    "# ================================================================================================\n",
    "\n",
    "def get_sample_workflows():\n",
    "    \"\"\"\n",
    "    Predefined workflow templates for common use cases\n",
    "    \"\"\"\n",
    "    \n",
    "    workflows = {\n",
    "        \"data_processing_workflow\": {\n",
    "            \"description\": \"Generate data, then analyze it\",\n",
    "            \"workflow\": [\n",
    "                {\n",
    "                    \"agent\": \"data_generator\",\n",
    "                    \"params\": {\n",
    "                        \"dataset_type\": \"customers\",\n",
    "                        \"count\": 50\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"agent\": \"analytics\",\n",
    "                    \"params\": {\n",
    "                        \"data\": \"{{previous_result.dataset}}\",  # Placeholder for chaining\n",
    "                        \"analysis_type\": \"summary\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \n",
    "        \"text_and_math_workflow\": {\n",
    "            \"description\": \"Process text and do calculations\",\n",
    "            \"workflow\": [\n",
    "                {\n",
    "                    \"agent\": \"text_processor\",\n",
    "                    \"params\": {\n",
    "                        \"text\": \"Hello AgentCore World\",\n",
    "                        \"operations\": [\"uppercase\", \"word_count\", \"character_count\"]\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"agent\": \"calculator\",\n",
    "                    \"params\": {\n",
    "                        \"operation\": \"multiply\",\n",
    "                        \"numbers\": [10, 20, 3]\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \n",
    "        \"comprehensive_workflow\": {\n",
    "            \"description\": \"Multi-step workflow using all agents\",\n",
    "            \"workflow\": [\n",
    "                {\n",
    "                    \"agent\": \"data_generator\",\n",
    "                    \"params\": {\n",
    "                        \"dataset_type\": \"sales\",\n",
    "                        \"count\": 25\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"agent\": \"analytics\",\n",
    "                    \"params\": {\n",
    "                        \"data\": \"{{previous_result.dataset}}\",\n",
    "                        \"analysis_type\": \"summary\"\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"agent\": \"text_processor\", \n",
    "                    \"params\": {\n",
    "                        \"text\": \"Analysis Complete: Data Quality Check Passed\",\n",
    "                        \"operations\": [\"uppercase\", \"word_count\"]\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"agent\": \"calculator\",\n",
    "                    \"params\": {\n",
    "                        \"operation\": \"average\",\n",
    "                        \"numbers\": [95, 87, 92, 89, 94]  # Quality scores\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return workflows\n",
    "\n",
    "\n",
    "# ================================================================================================\n",
    "# TESTING AND DEPLOYMENT FUNCTIONS\n",
    "# ================================================================================================\n",
    "\n",
    "async def test_individual_agents():\n",
    "    \"\"\"Test each agent individually\"\"\"\n",
    "    \n",
    "    print(\"🧪 Testing Individual Agents\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Mock context for testing\n",
    "    class MockContext:\n",
    "        async def ping(self, status, message):\n",
    "            print(f\"🔄 {message}\")\n",
    "    \n",
    "    context = MockContext()\n",
    "    \n",
    "    # Test Calculator Agent\n",
    "    print(\"\\n1️⃣ Testing Calculator Agent\")\n",
    "    calc_result = await calculator_agent({\n",
    "        \"operation\": \"add\",\n",
    "        \"numbers\": [10, 20, 30]\n",
    "    }, context)\n",
    "    print(f\"Result: {calc_result}\")\n",
    "    \n",
    "    # Test Text Processor Agent\n",
    "    print(\"\\n2️⃣ Testing Text Processor Agent\")\n",
    "    text_result = await text_processor_agent({\n",
    "        \"text\": \"Amazon Bedrock AgentCore\",\n",
    "        \"operations\": [\"uppercase\", \"word_count\", \"reverse\"]\n",
    "    }, context)\n",
    "    print(f\"Result: {text_result}\")\n",
    "    \n",
    "    # Test Data Generator Agent\n",
    "    print(\"\\n3️⃣ Testing Data Generator Agent\")\n",
    "    data_result = await data_generator_agent({\n",
    "        \"dataset_type\": \"customers\",\n",
    "        \"count\": 5\n",
    "    }, context)\n",
    "    print(f\"Generated {len(data_result['dataset'])} records\")\n",
    "    print(f\"Sample record: {data_result['dataset'][0]}\")\n",
    "    \n",
    "    # Test Analytics Agent\n",
    "    print(\"\\n4️⃣ Testing Analytics Agent\")\n",
    "    analytics_result = await simple_analytics_agent({\n",
    "        \"data\": data_result['dataset'],\n",
    "        \"analysis_type\": \"summary\"\n",
    "    }, context)\n",
    "    print(f\"Analytics: {analytics_result['analytics']}\")\n",
    "    print(f\"Insights: {analytics_result['insights']}\")\n",
    "    \n",
    "    return {\n",
    "        \"calculator\": calc_result,\n",
    "        \"text_processor\": text_result, \n",
    "        \"data_generator\": data_result,\n",
    "        \"analytics\": analytics_result\n",
    "    }\n",
    "\n",
    "\n",
    "async def test_orchestration():\n",
    "    \"\"\"Test the orchestration capabilities\"\"\"\n",
    "    \n",
    "    print(\"\\n🔀 Testing Orchestration\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    class MockContext:\n",
    "        async def ping(self, status, message):\n",
    "            print(f\"🔄 {message}\")\n",
    "    \n",
    "    context = MockContext()\n",
    "    \n",
    "    # Test simple workflow\n",
    "    simple_workflow = {\n",
    "        \"workflow\": [\n",
    "            {\n",
    "                \"agent\": \"data_generator\",\n",
    "                \"params\": {\n",
    "                    \"dataset_type\": \"products\",\n",
    "                    \"count\": 10\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"agent\": \"calculator\",\n",
    "                \"params\": {\n",
    "                    \"operation\": \"average\",\n",
    "                    \"numbers\": [100, 200, 150, 300, 250]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"agent\": \"text_processor\",\n",
    "                \"params\": {\n",
    "                    \"text\": \"Orchestration Test Complete\",\n",
    "                    \"operations\": [\"title_case\", \"word_count\"]\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    orchestration_result = await simple_orchestrator(simple_workflow, context)\n",
    "    \n",
    "    print(f\"\\nOrchestration Status: {orchestration_result['overall_status']}\")\n",
    "    print(f\"Steps Completed: {orchestration_result['summary']['successful_steps']}/{orchestration_result['summary']['total_steps']}\")\n",
    "    print(f\"Total Duration: {orchestration_result['summary']['total_duration_seconds']:.2f} seconds\")\n",
    "    \n",
    "    return orchestration_result\n",
    "\n",
    "\n",
    "def generate_deployment_config():\n",
    "    \"\"\"Generate deployment configuration for AgentCore\"\"\"\n",
    "    \n",
    "    config = {\n",
    "        \"agentcore_config\": {\n",
    "            \"entry_point\": \"simple_agentcore_system.py\",\n",
    "            \"runtime_settings\": {\n",
    "                \"timeout_hours\": 1,\n",
    "                \"memory_mb\": 512,\n",
    "                \"environment_variables\": {\n",
    "                    \"AGENT_ENVIRONMENT\": \"development\"\n",
    "                }\n",
    "            },\n",
    "            \"agents\": [\n",
    "                {\n",
    "                    \"name\": \"calculator_agent\",\n",
    "                    \"description\": \"Performs basic mathematical operations\",\n",
    "                    \"entry_point\": \"calculator_agent\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"text_processor_agent\", \n",
    "                    \"description\": \"Processes and transforms text\",\n",
    "                    \"entry_point\": \"text_processor_agent\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"data_generator_agent\",\n",
    "                    \"description\": \"Generates sample datasets\",\n",
    "                    \"entry_point\": \"data_generator_agent\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"simple_analytics_agent\",\n",
    "                    \"description\": \"Performs basic data analysis\",\n",
    "                    \"entry_point\": \"simple_analytics_agent\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"simple_orchestrator\",\n",
    "                    \"description\": \"Coordinates multiple agents\",\n",
    "                    \"entry_point\": \"simple_orchestrator\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return config\n",
    "\n",
    "\n",
    "# ================================================================================================\n",
    "# MAIN EXECUTION\n",
    "# ================================================================================================\n",
    "\n",
    "async def main():\n",
    "    \"\"\"Main function to test the simple agent system\"\"\"\n",
    "    \n",
    "    print(\"🤖 Simple AgentCore System with Orchestration\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Test individual agents\n",
    "        individual_results = await test_individual_agents()\n",
    "        \n",
    "        # Test orchestration\n",
    "        orchestration_result = await test_orchestration()\n",
    "        \n",
    "        # Show available workflows\n",
    "        workflows = get_sample_workflows()\n",
    "        print(f\"\\n📋 Available Workflow Templates:\")\n",
    "        for name, workflow in workflows.items():\n",
    "            print(f\"  • {name}: {workflow['description']}\")\n",
    "        \n",
    "        # Generate deployment config\n",
    "        deployment_config = generate_deployment_config()\n",
    "        \n",
    "        print(f\"\\n✅ Simple AgentCore system tested successfully!\")\n",
    "        print(f\"🚀 Ready for deployment to AgentCore Runtime\")\n",
    "        \n",
    "        return {\n",
    "            \"individual_tests\": individual_results,\n",
    "            \"orchestration_test\": orchestration_result,\n",
    "            \"deployment_config\": deployment_config\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Test failed: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the test\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cf4318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
